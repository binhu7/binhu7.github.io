<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Bin Hu &ndash; Research </title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Bin Hu</div>
<div class="menu-item"><a href="index.html">home</a></div>
<div class="menu-item"><a href="research.html"class="current">Research</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Research <br /></h1>
</div>
<p> I am interested
in building fundamental connections between the techniques used in the control and machine learning
communities.   Specifically, my current research focuses on developing new analysis/design/validation tools that ensure an efficient and safe integration of control
and learning techniques for next generation intelligent systems such as self-driving cars, advanced robotics, and smart buildings. </p>

<h2>Control Tools for Generalization in Deep Learning</h2>
<p>Deep learning techniques have been used to achieve the state-of-the-art performance for a variety of applications (computer vision, natural language processing, and Go). 
However, the generalization mechanism in training overparameterized deep models is still unclear.
This research focuses on tailoring various tools  from robust control, risk sensitive control, adaptive control, and stochastic control for understanding the interplay between generalization and non-convex optimization in deep learning.
  The starting point for this research is a dynamical system perspective on the training algorithms in deep learning.
  </p>

<h2>Combining Robust Control and Deep Reinforcement Learning for Safety-Critical AI</h2>
<p>I am interested in reconciling robust control with deep reinforcement learning for safety-critical AI applications. I
am currently investigating the convergence properties of model-free policy gradient methods for various standard robust
control tasks. I am also developing new robust reinforcement learning methods by leveraging ideas from robust control and risk sensitive control.
Finally, I am working on control validation tools that can be used to certify the robustness and safety of interconnected systems with deep neural nets in the loop.  </p>


<h2>Optimization is Control</h2>
<p> Optimization can be viewed as a control problem. By viewing the gradient of the cost function
as a plant one wants to control, the optimization problem becomes an output regulation control problem.
Consequently, first-order optimization methods can be viewed as controllers regulating the plant. For example, gradient descent,
Nesterov’s method, and heavy-ball method can all be viewed as special cases of the proportional-integral-derivative
(PID) controllers. My current research focus is on translating “controllers” into “optimization
methods” for large-scale unconstrained and constrained optimization problems in machine learning, control, robotics, smart buildings, and power systems.</p>



</td>
</tr>
</table>
</body>
</html>
